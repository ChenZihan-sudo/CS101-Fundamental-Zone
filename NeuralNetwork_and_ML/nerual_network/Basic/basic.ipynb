{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin shape:  torch.Size([8, 8])\n",
      "val:  tensor([[0.2193, 0.2986, 0.7369, 0.4558, 0.3182, 0.0898, 0.6697, 0.8750],\n",
      "        [0.4193, 0.0449, 0.4611, 0.5393, 0.4810, 0.9562, 0.6900, 0.7516],\n",
      "        [0.7703, 0.8017, 0.0812, 0.7176, 0.5509, 0.8178, 0.9061, 0.8752],\n",
      "        [0.9974, 0.9965, 0.7936, 0.6669, 0.9015, 0.2794, 0.3011, 0.9082],\n",
      "        [0.4097, 0.9661, 0.3289, 0.0406, 0.7023, 0.9485, 0.9419, 0.4979],\n",
      "        [0.1865, 0.1421, 0.1349, 0.4432, 0.0478, 0.8625, 0.3974, 0.3051],\n",
      "        [0.9248, 0.9113, 0.0279, 0.9343, 0.3375, 0.9359, 0.9647, 0.7873],\n",
      "        [0.4773, 0.8177, 0.5523, 0.5237, 0.2553, 0.0708, 0.4847, 0.5209]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.rand(size=(8, 8))\n",
    "print(\"origin shape: \", x.shape)\n",
    "print(\"val: \", x)\n",
    "\n",
    "# torch.nn.functional.conv2d(input, kernel_size=3, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catcolia/anaconda3/envs/NN/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(out_channels=1, kernel_size=(3, 3), stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]], requires_grad=True)\n",
      "shape:  (1, 1, 8, 8)\n",
      "x:  tensor([[[[0.2193, 0.2986, 0.7369, 0.4558, 0.3182, 0.0898, 0.6697, 0.8750],\n",
      "          [0.4193, 0.0449, 0.4611, 0.5393, 0.4810, 0.9562, 0.6900, 0.7516],\n",
      "          [0.7703, 0.8017, 0.0812, 0.7176, 0.5509, 0.8178, 0.9061, 0.8752],\n",
      "          [0.9974, 0.9965, 0.7936, 0.6669, 0.9015, 0.2794, 0.3011, 0.9082],\n",
      "          [0.4097, 0.9661, 0.3289, 0.0406, 0.7023, 0.9485, 0.9419, 0.4979],\n",
      "          [0.1865, 0.1421, 0.1349, 0.4432, 0.0478, 0.8625, 0.3974, 0.3051],\n",
      "          [0.9248, 0.9113, 0.0279, 0.9343, 0.3375, 0.9359, 0.9647, 0.7873],\n",
      "          [0.4773, 0.8177, 0.5523, 0.5237, 0.2553, 0.0708, 0.4847, 0.5209]]]])\n",
      "conv2d bias: Parameter containing:\n",
      "tensor([0.0557], requires_grad=True)\n",
      "conv2d weight: Parameter containing:\n",
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]], requires_grad=True)\n",
      "conv2d shape: torch.Size([1, 1, 8, 8])\n",
      "tensor([[[[1.0378, 2.2358, 2.5924, 3.0481, 2.8961, 3.2606, 4.0880, 3.0419],\n",
      "          [2.6098, 3.8890, 4.1930, 4.3978, 4.9825, 5.5354, 6.6872, 4.8233],\n",
      "          [4.0858, 5.4216, 5.1585, 5.2488, 5.9664, 5.9397, 6.5414, 4.4880],\n",
      "          [4.9974, 6.2010, 5.4488, 4.8391, 5.6812, 6.4051, 6.5318, 4.4861],\n",
      "          [3.7541, 5.0114, 4.5684, 4.1153, 4.9484, 5.4379, 5.4976, 3.4072],\n",
      "          [3.5963, 4.0880, 3.9851, 3.0532, 5.3084, 6.1942, 6.6968, 3.9499],\n",
      "          [3.5155, 4.2306, 4.5432, 3.3126, 4.4667, 4.4123, 5.3850, 3.5159],\n",
      "          [3.1868, 3.7671, 3.8229, 2.6867, 3.1131, 3.1046, 3.8200, 2.8134]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def comp_conv2d(\n",
    "    conv2d: torch.nn.modules.conv.LazyConv2d, x: torch.Tensor, batch_size=1, channel=1\n",
    ") -> torch.nn.modules.conv.LazyConv2d:\n",
    "    # batch size, channel -> (batch_size, channel, height, width)\n",
    "    print(\"shape: \", (batch_size, channel) + x.shape)\n",
    "    x = x.reshape((batch_size, channel) + x.shape)\n",
    "    print(\"x: \", x)\n",
    "    y = conv2d(x)\n",
    "    return y\n",
    "\n",
    "\n",
    "conv2d.forward(torch.ones_like(torch.empty(1, 1, 8, 8)))\n",
    "conv2d.weight = nn.Parameter(torch.ones_like(conv2d.weight))\n",
    "print(conv2d.weight)\n",
    "\n",
    "conv2d_res = comp_conv2d(conv2d, x)\n",
    "conv2d.weight = nn.Parameter(torch.ones_like(conv2d.weight))\n",
    "print(\"conv2d bias:\", conv2d.bias)\n",
    "print(\"conv2d weight:\", conv2d.weight)\n",
    "print(\"conv2d shape:\", conv2d_res.shape)\n",
    "\n",
    "print(conv2d_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
